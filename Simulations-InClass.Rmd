---
title: "Simulations In-Class Project"
date: "Due October 13, 2017 at 11:59pm"
output:
  html_document


---

<style type="text/css">
.table {

    width: 80%;
    margin-left:10%; 
    margin-right:10%;
}
</style>
```{r,setup, echo=FALSE, cache=TRUE}
## numbers >= 10^5 will be denoted in scientific notation,
## and rounded to 2 digits
options(scipen = 3, digits = 3)
```




#Project Goals:



With this project we will simulate a famous probability problem. This will not require knowledge of probability or statistics but only the logic to follow the steps in order to simulate this problem. This is one way to solve problems by using the computer. 


Since you all have completed problem 1, you first step will be to work through each of your groupmates code for problem #1 and comment on what is happening. Then as a team move forward in on direction as you move on to the rest of the problems 2-5

 1. **Gambler's Ruin**: Suppose you have a bankroll of $1000 and make bets of $100 on a fair game. By simulating the outcome directly for at most 5000 iterations of the game (or hands), estimate:
    a. the probability that you have "busted" (lost all your money) by the time you have placed your one hundredth bet. 
    **ANSWER** 31.86%
    b. the probability that you have busted by the time you have placed your five hundredth bet by simulating the outcome directly. 
    **ANSWER** 64.64%
    c. the mean time you go bust, given that you go bust within the first 5000 hands.
    **ANSWER** On average our player goes "bust" on the 536 hand (conditional on busting within first 5,000 hands)
    d. the mean and variance of your bankroll after 100 hands (including busts).
    **NOTE** This question requires _so_ much data to be retained (if you want to output the results) that I feel my approach may have been incorrect but here's my answer.
    **ANSWER** The mean bankroll after 100 hands (making busts = 0), is 989.54 hands while the var of the bankrolls is 822349.1
    e. the mean and variance of your bankroll after 500 hands (including busts).
    **ANSWER** The mean is 997.44 and var is 2602370 
 
Note: you *must* stop playing if your player has gone bust. How will you handle this in the `for` loop?

``` {r echo = TRUE} 
# First attempt to simulate the Gambler's Ruin 
# Seems like we want to use a binomial distribution, since we have "n" independent trials where the result is either success (you won) or failure (you lost), according to a constant probability of success. This is NOT yet a Markov Chain since you do not change your strategy depending on wins / losses

set.seed(0) # for reproducibility

initialBankroll <- 1000 # start with $1,000 but will increment this
bet <- 100 # always bet $100 
pSuccess <- .5 # I assume a "fair" games means 50% chance to win 
numIteractions <- 5000 # could change for other simulations

gamblerSimulation <- function(initialBankroll = 1000, bet = 100, pSuccess = .5, numIteractions = 5000) {

  bankrollHistory <- rep(NA, numIteractions) # create a bankroll History
  bankrollHistory[1] <- initialBankroll # set beginning bankroll 
  
  for (i in 1:numIteractions) { # i is the "hand" the game is on (first, second, etc.)
    
    # Check whether our player can even play the game! 
    if (bankrollHistory[i] < 100) { # Our player doesn't have enough money to play
      output <- list("Bust", i, bankrollHistory)
      return(output)
    } else { # our player does have enough money to play 
      # Have our player play the hand with a 50% probability of winning 
      
      # EDITED to update bankrollHistory understanding
      bankrollHistory[i+1] <- bankrollHistory[i] + 200 * rbinom(1, 1, p = pSuccess) - 100
    }
  }
  output <- list("Not Bust", i, bankrollHistory)
  return(output)
}

# Simulate 5,000 versions of the game (with max 5,000 hands) 
simulations <- replicate(numIteractions, gamblerSimulation())

# To answer the first three questions easily, I'll extract only the "Bust" and "Hand" variables from the list simulations (leaving the Bankroll variable for later)
#lastHandSize <- unlist(simulations[2,])
#mean(lastHandSize[lastHandSize < 5000])

# Answering questions d and e requires a little different data (i.e., the entire bankroll history for each hand) which is ridiculously large 
# I would like to learn the most efficiency way to do this in the future please!!!
finalPay <- rep(NA, numIteractions)

for (i in 1:numIteractions) {
  finalPay[i] <- simulations[3,][[i]][100]
}

finalPay[is.na(finalPay)] <- 0 # convert NA (which means they busted) to 0 to calculate mean & var

mean(finalPay)
var(finalPay)

finalPayE <- rep(NA, numIteractions)

for (i in 1:numIteractions) {
  finalPayE[i] <- simulations[3,][[i]][500]
}

finalPayE[is.na(finalPayE)] <- 0 # convert NA (which means they busted) to 0 to calculate mean & var

mean(finalPayE)
var(finalPayE)
```

2. Repeat the previous problem with betting on black in American roulette, where the probability of winning on any spin is 18/38 for an even payout.

    a. the probability that you have "busted" (lost all your money) by the time you have placed your one hundredth bet. 
    **ANSWER** 50%
    b. the probability that you have busted by the time you have placed your five hundredth bet by simulating the outcome directly. 
    **ANSWER** 91.8%
    c. the mean time you go bust, given that you go bust within the first 5000 hands.
    **ANSWER** On average our player goes "bust" on the ~119 hand (conditional on busting within first 5,000 hands)
    
    d. the mean and variance of your bankroll after 100 hands (including busts).
    **NOTE** This question requires _so_ much data to be retained (if you want to output the results) that I feel my approach may have been incorrect but here's my answer.
    **ANSWER** The mean bankroll after 100 hands (making busts = 0), is 604.32 while the var of the bankrolls is 585098
    e. the mean and variance of your bankroll after 500 hands (including busts).
    **ANSWER** The mean is 161.64 and var is 408630 

``` {r echo = TRUE}

# If I understand correctly then I'm simply changing the probability of winning, which I have coded in my function so I can just adjust it to provide the simluations for this question. 

simulationAmericanRoulette <- replicate(numIteractions, gamblerSimulation(pSuccess = 18/38))

# To answer the first three questions easily, I'll extract only the "Bust" and "Hand" variables from the list simulations (leaving the Bankroll variable for later)
lastHandSize <- unlist(simulationAmericanRoulette[2,])
mean(lastHandSize[lastHandSize < 5000])

# Answering questions d and e requires a little different data (i.e., the entire bankroll history for each hand) which is ridiculously large 
# I would like to learn the most efficiency way to do this in the future please!!!
finalPay <- rep(NA, numIteractions)

for (i in 1:numIteractions) {
  finalPay[i] <- simulationAmericanRoulette[3,][[i]][100]
}

finalPay[is.na(finalPay)] <- 0 # convert NA (which means they busted) to 0 to calculate mean & var

mean(finalPay)
var(finalPay)

finalPayE <- rep(NA, numIteractions)

for (i in 1:numIteractions) {
  finalPayE[i] <- simulationAmericanRoulette[3,][[i]][500]
}

finalPayE[is.na(finalPayE)] <- 0 # convert NA (which means they busted) to 0 to calculate mean & var

mean(finalPayE)
var(finalPayE)
```

3. **Markov Chains**. Suppose you have a game where the probability of winning on your first hand is 48%; each time you win, that probability goes up by one percentage point for the next game (to a maximum of 100%, where it must stay), and each time you lose, it goes back down to 48%. Assume you cannot go bust and that the size of your wager is a constant $100.
    a. Is this a fair game? Simulate one hundred thousand sequential hands to determine the size of your return. Then repeat this simulation 99 more times to get a range of values to calculate the expectation.
    
    **ANSWER** No it's not a fair game. If you start at $0 and continue to play, on average your return -200158.
    b. Repeat this process but change the starting probability to a new value within 2% either way. Get the expected return after 100 repetitions. Keep exploring until you have a return value that is as fair as you can make it. Can you do this automatically?
    
    **ANSWER** As you can see from my graph, the overall winnings cross from negative to positive in between the probabilities 47% and 49%. So a value close to initial chance of winning at 49% would be a fair game. 
    
    c. Repeat again, keeping the initial probability at 48%, but this time change the probability increment to a value different from 1%. Get the expected return after 100 repetitions. Keep changing this value until you have a return value that is as fair as you can make it. 
    
    **ANSWER** As you can see from the plot, the overall winnings cross from negative to positive when the Markov increment for the probability of winning is between 1.2% and 1.3%. So a value inbetween there would be the "fair" amount if the initial probability of winning is 48%. 
    
``` {r echo = TRUE} 

initalProbWin <- .48 # inital probability of winning
probIncrement <- .01 # change in probability of winning after getting a win
initalBankroll <- 0 # starting $
bet <- 100 # how much you bet each trial
numTrials <- 100000 # 100,000 trials 

markovSim <- function(initalBankroll = 0, bet = 100, initalProbWin = .48, probIncrement = .01, numTrials = 100000) {
  
  bankrollHistory <- rep(NA, numTrials)
  bankrollHistory[1] <- initalBankroll
  
  probTrial <- rep(NA, numTrials)
  probTrial[1] <- initalProbWin
  
  for (i in 1:numTrials) { # i is the "hand" the game is on (first, second, etc.)
    # Markov chain
    trialSuccess <- rbinom(1, 1, probTrial[i]) 
    
    bankrollHistory[i+1] <- bankrollHistory[i] + 200 * trialSuccess - 100
    
    # Update probability in probTrial[i] based on trialSucces 1 or 0 
    if (trialSuccess == 1) { # won!
      probTrial[i + 1] <- probTrial[i] + probIncrement  
    } else {
      probTrial[i + 1] <-initalProbWin # set back to .48
    }
    
    # Add if to ensure probability can't go above 1
    if (probTrial[i + 1] > 1) {
      probTrial[i + 1] <- 1
    } else {
      next()
    }
  }
  return(bankrollHistory)
}

# markovSim()

simulationMarkovAnswers <- replicate(100, markovSim()) # will output a 100,000 by 100 matrix where each col is simulation

# Answer A
mean(simulationMarkovAnswers[numTrials, 1:100]) # pull last number out of each sim and average

## Answer B, testing various probabilities 

rangeProb <- seq(.05, .95, by = .02) # range of probabilities to test
meanSim <- rep(NA, length(rangeProb))

markovRange <- data.frame(rangeProb, meanSim)

startTime <- Sys.time()

for (i in 1:length(rangeProb)) { 
  initalProbWin <- rangeProb[i]
  
  simulationMarkovAnswers <- replicate(100, markovSim(initalProbWin = initalProbWin)) 

  markovRange$meanSim[i] <- mean(simulationMarkovAnswers[numTrials, 1:100]) # pull last number out of each sim and average
}

endTime <- Sys.time()

totalTime <- round(endTime - startTime, 2)

print(paste0("Simulation took ", totalTime, " hours")) # I kind of cheated since I hardcoded "hours"

library(ggplot2)
plotSim <- ggplot(markovRange, aes(x = rangeProb, y = meanSim)) + 
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, color = "red")
plotSim

## Answer C
markovProbIncrease <- seq(.01, .10, by = .001) # range of increases in prob to win to test
meanSim <- rep(NA, length(markovProbIncrease))

markovRange <- data.frame(markovProbIncrease, meanSim)

startTime <- Sys.time()

for (i in 1:length(markovProbIncrease)) { 
  probIncrement <- markovProbIncrease[i]
  
  simulationMarkovAnswers <- replicate(100, markovSim(probIncrement = probIncrement)) 

  markovRange$meanSim[i] <- mean(simulationMarkovAnswers[numTrials, 1:100]) # pull last number out of each sim and average
}

endTime <- Sys.time()

totalTime <- round(endTime - startTime, 2)

print(paste0("Simulation took ", totalTime, " minutes")) # I kind of cheated since I hardcoded "minutes"

library(ggplot2)
plotSim <- ggplot(markovRange, aes(x = markovProbIncrease, y = meanSim)) + 
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, color = "red")
plotSim
```


4. Creating a Bootstrap function. There is a particular concept called [bootstrapping]
(https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) where we can easily create 95% confidence intervals, even for complex estimators.

The steps of this process are:

  a. Draw a sample, with replacement, from your data which is the same length of your data.
  b. Calculate the statistic of interest on this boostrap sample (ie mean, variance, regression,...)
  c. Peform steps 1:2 at least 1000 times over until you have a vector of your statistics. 
  d. The lower bound of a 95% CI will be the 0.025 percentile
  e. The upper bound of a 95% CI will be the 0.975 percentile

Make a function called `boot_ci` which calculates the 95% confidence interval in this manner. 

``` {r echo = TRUE}

data = 1:100
numIteration = 1000

boot_ci <- function(data, numIteration = 1000) {
  # Initalize vector of statistics 
  meanBoots <- rep(NA, numIteration)
  
  # Bootstrap procedure
  for (i in 1:numIteration) {
    # Create bootstrap sample and do statistic on it
    bootData <- sample(data, replace = T) # draw a sample with replacement from data
    meanBoots[i] <- mean(bootData)
  }
  
  # Compute 95% confidence interval 
  ciBounds <- quantile(meanBoots, c(.025, .975))
  return(ciBounds)
}

boot_ci(data)

```
```

5. For problems 3b and 3c, you calculated a mean value. Because you saved these final results in a vector, use the bootstrap to estimate the variance of the return in each case for your final answer. Once you have these results, which game has the smaller variance in returns?